# ğŸ›¡ï¸ ModÃ©ration de Contenu avec NSFW.js

Ce projet utilise **NSFW.js** pour la modÃ©ration automatique des photos envoyÃ©es dans le chat.

## ğŸ¯ Pourquoi NSFW.js ?

- **100% Gratuit** - Pas de limite d'utilisation
- **Local & PrivÃ©** - Les images ne quittent pas votre serveur
- **Rapide** - Analyse en ~100-300ms
- **Open Source** - BasÃ© sur TensorFlow.js
- **Facile** - Aucune configuration requise

## ğŸ” Comment Ã§a fonctionne ?

### 1. Chargement du modÃ¨le
Au dÃ©marrage du serveur, NSFW.js charge automatiquement son modÃ¨le de deep learning :

```
ğŸ¤– Loading NSFW.js model...
âœ… NSFW.js model loaded successfully
```

### 2. Analyse des images
Quand un utilisateur envoie une photo, NSFW.js l'analyse et retourne des scores :

```typescript
{
  Porn: 0.05,      // 5% - Pornographie explicite
  Sexy: 0.15,      // 15% - Contenu sexy/suggestif
  Hentai: 0.02,    // 2% - Contenu hentai
  Neutral: 0.75,   // 75% - Contenu neutre
  Drawing: 0.03    // 3% - Dessin NSFW
}
```

### 3. DÃ©cision de modÃ©ration
Le service compare les scores aux seuils configurÃ©s :

| CatÃ©gorie | Seuil | Action |
|-----------|-------|--------|
| Porn      | 60%   | âš ï¸ Avertissement |
| Sexy      | 70%   | âš ï¸ Avertissement |
| Hentai    | 60%   | âš ï¸ Avertissement |

### 4. Notification utilisateur
Si du contenu sensible est dÃ©tectÃ©, le rÃ©cepteur voit un avertissement avant d'ouvrir la photo :

```
âš ï¸ Contenu sensible dÃ©tectÃ©
Cette photo contient possiblement du contenu sensible. Soyez prudent.
```

## âš™ï¸ Configuration des seuils

Vous pouvez ajuster les seuils dans `moderation.service.ts:92-94` :

```typescript
const PORN_THRESHOLD = 0.6;   // 60% (dÃ©faut)
const SEXY_THRESHOLD = 0.7;   // 70% (dÃ©faut)
const HENTAI_THRESHOLD = 0.6; // 60% (dÃ©faut)
```

**Recommandations :**
- **TrÃ¨s strict** : 0.4-0.5 (40-50%)
- **Ã‰quilibrÃ©** : 0.6-0.7 (60-70%) âœ… DÃ©faut
- **Permissif** : 0.8-0.9 (80-90%)

## ğŸ“Š Logs de modÃ©ration

Le service log toutes les analyses :

```bash
# Photo sÃ»re
ğŸ” Analyzing image: photo_1234567890_abc123.jpg
âœ… Image passed moderation (neutral: 85.3%)

# Photo avec contenu sensible
ğŸ” Analyzing image: photo_1234567890_def456.jpg
âš ï¸ Porn detected: 72.4%
âš ï¸ Sexy content detected: 81.2%
```

## ğŸš€ Performance

- **PremiÃ¨re analyse** : ~2-3 secondes (chargement du modÃ¨le)
- **Analyses suivantes** : ~100-300ms
- **MÃ©moire** : ~150-200 MB (modÃ¨le chargÃ© en RAM)
- **CPU** : Utilisation du backend TensorFlow CPU

## ğŸ§ª Test de la modÃ©ration

### 1. DÃ©marrer le serveur
```bash
npm run start:dev
```

### 2. VÃ©rifier les logs
```
ğŸ¤– Loading NSFW.js model...
âœ… NSFW.js model loaded successfully
```

### 3. Envoyer une photo de test
Utilisez l'interface frontend pour envoyer une photo et observez les logs du backend.

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨me : Le modÃ¨le ne se charge pas
**SymptÃ´me :**
```
âŒ Failed to load NSFW.js model: ...
```

**Solutions :**
1. VÃ©rifier que les packages sont installÃ©s :
   ```bash
   npm install nsfwjs @tensorflow/tfjs canvas
   ```

2. VÃ©rifier la connexion internet (premiÃ¨re fois seulement)
   Le modÃ¨le est tÃ©lÃ©chargÃ© depuis CDN au premier lancement

3. VÃ©rifier les logs pour plus de dÃ©tails

### ProblÃ¨me : Analyse trÃ¨s lente
**Causes possibles :**
- PremiÃ¨re analyse (chargement du modÃ¨le)
- Image trÃ¨s haute rÃ©solution

**Solutions :**
- Redimensionner les images avant l'upload
- Augmenter les ressources CPU du serveur

## ğŸ” SÃ©curitÃ© & ConfidentialitÃ©

âœ… **Analyse locale** - Les images ne sont jamais envoyÃ©es Ã  un service tiers
âœ… **Pas de stockage** - Le modÃ¨le analyse sans conserver les images
âœ… **Open source** - Code vÃ©rifiable et auditable
âœ… **Sans API externe** - Pas de dÃ©pendance Ã  un service cloud

## ğŸ“š Ressources

- [NSFW.js GitHub](https://github.com/infinitered/nsfwjs)
- [TensorFlow.js](https://www.tensorflow.org/js)
- [Documentation complÃ¨te](https://github.com/infinitered/nsfwjs#usage)

## ğŸ“ ModÃ¨le utilisÃ©

NSFW.js utilise un modÃ¨le MobileNetV2 entraÃ®nÃ© sur des millions d'images :
- Taille : ~4.5 MB
- PrÃ©cision : ~93% sur les tests
- EntraÃ®nÃ© sur : Images du domaine public

## ğŸ“ Notes importantes

1. **Aucun filtre n'est parfait** - VÃ©rifications manuelles recommandÃ©es pour les cas limites
2. **Faux positifs possibles** - Certaines images innocentes peuvent Ãªtre marquÃ©es
3. **Faux nÃ©gatifs possibles** - Certains contenus sensibles peuvent passer
4. **Ã‰volution continue** - Le modÃ¨le est rÃ©guliÃ¨rement mis Ã  jour

## ğŸ’¡ Alternatives envisagÃ©es

| Service | CoÃ»t | PrÃ©cision | Vie privÃ©e | Choix |
|---------|------|-----------|------------|-------|
| Sightengine | $49/mois | 95% | âš ï¸ Cloud | âŒ |
| AWS Rekognition | Variable | 94% | âš ï¸ Cloud | âŒ |
| Google Vision | Variable | 96% | âš ï¸ Cloud | âŒ |
| **NSFW.js** | **Gratuit** | **93%** | **âœ… Local** | **âœ…** |
